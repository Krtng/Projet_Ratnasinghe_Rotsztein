{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcaNzO4dLQ3g"
      },
      "source": [
        "## Introduction à la quantization \n",
        "\n",
        "Laurent cetinsoy\n",
        "\n",
        "Les réseaux de neurones prennent beaucoup de place et il peut être difficile de les faire rentrer sur certains dispositifs embarqués. \n",
        "\n",
        "Il existe plusieurs méthodes pour réduire la taille et augmenter la vitesse d'executer des réseaux de neurone. Par exemple il y a ce qu'on appelle la quantization et le pruning.\n",
        "\n",
        "Dans ce notebook on va faire une introduction à la quantization avec la librairie tensorflow lite.\n",
        "\n",
        "\n",
        "## Quantization post training\n",
        "\n",
        "Dans un premier temps on va quantifier notre réseau après l'avoir entraîné normalement. \n",
        "\n",
        "\n",
        "Entraîner un réseau de neurone convolutionnel simple avec keras pour faire de la classification MNIST (ou un autre dataset simple de votre choix si (vous en avez marre de ce dataset - https://keras.io/api/datasets/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xh_7MEdLLQ3i",
        "outputId": "f4d7b83a-df65-4831-ebf9-001ca15403e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.3175 - accuracy: 0.9096 - val_loss: 155.8039 - val_accuracy: 0.7285\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd29e7120a0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset = load_data()\n",
        "train, test = dataset\n",
        "X_train, y_train = train\n",
        "X_test, y_test = test\n",
        "\n",
        "print(type(X_train))\n",
        "# (X_train.shape) Pour afficher les dimensions\n",
        "\n",
        "X_train = X_train.reshape(-1, 28, 28, 1) / 255 # -1 signifie qu il calcule auto le nb d elements\n",
        "#X_train = X_train.reshape(60000, 28, 28, 1)\n",
        "# /255 signifie une normalisation des donnees\n",
        "\n",
        "# En augmentant le nombre de couches ou les params, le modele ne se televerse plus sur l arduino\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(2, 2), activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2), strides=None))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Modele vise a l origine mais qu on a pas pu implementer par des contraintes de poids :\n",
        "#model.add(Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "#model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "#model.add(MaxPooling2D((2, 2), strides=None))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(units=10, activation='softmax', input_shape=(28**2, )))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
        "# Validation_data pour calculer un score sur le test\n",
        "# On peut rajouter des epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMhXSMFALQ3i"
      },
      "source": [
        "Afficher le nombre de paramètre du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LJOTxIN-LQ3j",
        "outputId": "c001ddbc-4f74-4b83-b800-52341331d5d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 27, 27, 16)        80        \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2704)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                27050     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,130\n",
            "Trainable params: 27,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary() # DOnne la structure du reseau et le nb de params par couche\n",
        "# Pooling pour reduire la taille de l image\n",
        "# Le nombre de paramatres va drastiquement diminuer avec unn max pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMSec_HkLQ3j"
      },
      "source": [
        "Sauvegarder votre modèle et afficher la taille du fichier. Si on applique une bête règle de trois, quelle est la taille occupée par paramètre ? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LSBmkN2SLQ3j",
        "outputId": "d0341133-1ecc-4ec0-e02e-89fe92bc3aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
            "...layers\n",
            "......conv2d\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......dense\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......flatten\n",
            ".........vars\n",
            "......max_pooling2d\n",
            ".........vars\n",
            "...metrics\n",
            "......mean\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......mean_metric_wrapper\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "...optimizer\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            ".........2\n",
            ".........3\n",
            ".........4\n",
            ".........5\n",
            ".........6\n",
            ".........7\n",
            ".........8\n",
            "...vars\n",
            "Keras model archive saving:\n",
            "File Name                                             Modified             Size\n",
            "metadata.json                                  2023-03-27 19:48:39           64\n",
            "config.json                                    2023-03-27 19:48:39         1910\n",
            "variables.h5                                   2023-03-27 19:48:39       350072\n",
            "\n",
            "Le fichier a une taille de : 352463 octets.\n",
            "La taille d'un parametre est de : 0.9096617509665365 octets\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import os.path\n",
        "\n",
        "joblib.dump(model, \"embedded_network.joblib\")\n",
        "\n",
        "file_size = os.path.getsize(\"embedded_network.joblib\")\n",
        "print(f\"\\nLe fichier a une taille de : {file_size} octets.\")\n",
        "\n",
        "# Pour obtenir la taille d'un parametre, on va diviser la taille du fichier par le nombre de parametres.\n",
        "param_size = file_size / 387466\n",
        "print(f\"La taille d'un parametre est de : {param_size} octets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBm7IyGSLQ3k"
      },
      "source": [
        "On va maintenant convertir notre modèle keras en modèle tensorflow lite. \n",
        "\n",
        "Installer la librairie tensorflow lite créer une instance de la class TFLiteConverter à partir de votre modèle keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "maLyE8Q2LQ3k"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YOQnDlWLQ3k"
      },
      "source": [
        "Convertir votre modèle et le sauvegarder dans un fichier nommé model.tflite. Sa taille est-elle plus petite ? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IMH-7ipsLQ3k",
        "outputId": "bd7917e4-b01a-4100-981c-6238120052ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ce nouveau fichier model.tflite fait 110897 octets.\n",
            "Il est donc plus petit que l ancien fichier.\n"
          ]
        }
      ],
      "source": [
        "tflite_model = converter.convert()\n",
        "\n",
        "joblib.dump(tflite_model, \"model.tflite\")\n",
        "\n",
        "tflite_size = os.path.getsize(\"model.tflite\")\n",
        "print(f\"\\nCe nouveau fichier model.tflite fait {tflite_size} octets.\")\n",
        "print(\"Il est donc plus petit que l ancien fichier.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrjsBZ-YLQ3k"
      },
      "source": [
        "On va maintenant spécifier des optimisations au converter. \n",
        "\n",
        "1. Recréer un converter\n",
        "\n",
        "2. modifier son attribut optimizations pour ajouter une liste d'optimisation avec la valeur tf.lite.Optimize.DEFAULT\n",
        "\n",
        "3. Relancer la conversion du modèle, sauvegarder le modèle et regarder la taille du fichier généré"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BB5sKzAyLQ3l",
        "outputId": "6e08e93c-0e5e-45c5-cc86-8028e9cd3f31"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Apres optimisation, ce nouveau fichier model.tflite fait 29874 octets.\n",
            "Il est donc plus petit que l ancien fichier.\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "new_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "#2\n",
        "new_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "#3\n",
        "new_tflite_model = new_converter.convert()\n",
        "joblib.dump(new_tflite_model, \"new_model.tflite\")\n",
        "\n",
        "new_tflite_size = os.path.getsize(\"new_model.tflite\")\n",
        "print(f\"\\nApres optimisation, ce nouveau fichier model.tflite fait {new_tflite_size} octets.\")\n",
        "print(\"Il est donc plus petit que l ancien fichier.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaXY7vTeLQ3l"
      },
      "source": [
        "Quelle type  de quantization Optimize.Default, utilise-t-elle ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7t4NtsqLQ3l"
      },
      "source": [
        "L'option Optimize.DEFAULT(tf.lite.Optimize.DEFAULT)utilisée par le convertisseur TFLite applique ici une optimisation complète du modèle, y compris la quantification dynamique des poids, l'optimisation des formats de données d'entrée et de sortie et la fusion arithmétique. Cette option réduit également la taille du modèle en utilisant des techniques de compression tout en maintenant une qualité de performance comparable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIx-ORJOLQ3l"
      },
      "source": [
        "## Quantization aware training \n",
        "\n",
        "Dans cette section on va s'intéresser à l'entraînement sensible à la quantification. L'idée est de simuler les effets de la quantification pendant l'entraînement pour que le modèle ajuste les poids afin de tenir ocmpte de la quantification. \n",
        "\n",
        "Reprendre le modèle entraîné sur MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DJdiFoe5DH4x",
        "outputId": "a71f92b6-31f9-425a-c177-50a21032f072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 27, 27, 16)        80        \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2704)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                27050     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,130\n",
            "Trainable params: 27,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EqLFZ-oLQ3m"
      },
      "source": [
        "A l'aide de la fonction quantize de tensorflow_model_optimization, créer une seconde version de votre modèle entraîné nommé qat_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1hhJqIuzDo-m",
        "outputId": "1b9b68e6-b2d4-44d5-ef51-55f08cde5893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.9/dist-packages (0.7.3)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "qat_model = tfmot.quantization.keras.quantize_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnB0C3YtLQ3m"
      },
      "source": [
        "Compiler le modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UsUN64HlEOes"
      },
      "outputs": [],
      "source": [
        "qat_model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6VBxcaRLQ3m"
      },
      "source": [
        "Afficher le summury du modèle. D'après vous ce modèle est-il quantifié ? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2eYRuz89ElBo",
        "outputId": "284e2ad5-6aff-4da3-f567-8e3e2d5297e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer_2 (QuantizeL  (None, 28, 28, 1)        3         \n",
            " ayer)                                                           \n",
            "                                                                 \n",
            " quant_conv2d_2 (QuantizeWra  (None, 27, 27, 16)       115       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_max_pooling2d_1 (Quan  (None, 13, 13, 16)       1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_flatten_2 (QuantizeWr  (None, 2704)             1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dense_2 (QuantizeWrap  (None, 10)               27055     \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,175\n",
            "Trainable params: 27,130\n",
            "Non-trainable params: 45\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "qat_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv5AmGbhEzJg"
      },
      "source": [
        "Le modèle est quantifié car après l'utilisation de la fonction tfmot.quantization.keras.quantize_model(), le nom des couches est précédé par le prefixe 'quant' qui signifie que le modèle est quantifié"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu_uBmoeLQ3n"
      },
      "source": [
        "Réentraîner votre modèle sur un sous ensemble des modèles sur une ou deux epochs et afficher la performance sur le train et test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GxyliM_KFXG-",
        "outputId": "fe4a793d-4ccf-4180-aa33-c5f25bb152e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 32s 16ms/step - loss: 0.1533 - accuracy: 0.9570\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1136 - accuracy: 0.9690\n",
            "Train loss: 0.11355474591255188\n",
            "Train accuracy: 0.968999981880188\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2181 - accuracy: 0.9364\n",
            "Test loss: 0.21807856857776642\n",
            "Test accuracy: 0.9363999962806702\n"
          ]
        }
      ],
      "source": [
        "qat_model.fit(X_train, y_train, epochs=1)\n",
        "\n",
        "train_loss, train_acc = qat_model.evaluate(X_train, y_train)\n",
        "print(\"Train loss:\", train_loss)\n",
        "print(\"Train accuracy:\", train_acc)\n",
        "\n",
        "test_loss, test_acc = qat_model.evaluate(X_test, y_test)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEioQfNhLQ3n"
      },
      "source": [
        "Convertir votre modèle avec TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "15TwBHbdLQ3n",
        "outputId": "224513cd-ca76-47fd-e141-7dae78d1275e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_2_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, flatten_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "qat_converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
        "qat_tflite_model = qat_converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR1XXXC5y6vO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=new_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "accuracy = 0\n",
        "count = 0\n",
        "input_details[0]['shape']\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    input_data = X_test[i].reshape(1, 28, 28,1).astype('float32')\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    #print(output, )\n",
        "    #print(y_test[i], np.argmax(output))\n",
        "\n",
        "    if np.argmax(output) == y_test[i]:\n",
        "      count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOvHD-EdzTMH"
      },
      "outputs": [],
      "source": [
        "# On calcul l'accuracy \n",
        "\n",
        "accuracy = count / (i+1)\n",
        "print(count, i+1)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm_i5nNi0l8d"
      },
      "outputs": [],
      "source": [
        "# On fait pareil avec QAT\n",
        "\n",
        "qat_tflite_model = qat_converter.convert()\n",
        "\n",
        "qat_interpreter = tf.lite.Interpreter(model_content=qat_tflite_model)\n",
        "qat_interpreter.allocate_tensors()\n",
        "\n",
        "qat_input_details = qat_interpreter.get_input_details()\n",
        "qat_output_details = qat_interpreter.get_output_details()\n",
        "\n",
        "qat_accuracy = 0\n",
        "qat_count = 0\n",
        "qat_input_details[0]['shape']\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    qat_input_data = X_test[i].reshape(1, 28, 28,1).astype('float32')\n",
        "    qat_interpreter.set_tensor(qat_input_details[0]['index'], qat_input_data)\n",
        "    qat_interpreter.invoke()\n",
        "    qat_output = qat_interpreter.get_tensor(qat_output_details[0]['index'])\n",
        "\n",
        "    if np.argmax(qat_output) == y_test[i]:\n",
        "      qat_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sejVs0yh1YdN"
      },
      "outputs": [],
      "source": [
        "# On calcul l'accuracy pour QAT\n",
        "\n",
        "qat_accuracy = qat_count / (i+1)\n",
        "print(qat_count, i+1)\n",
        "print(qat_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL2jxscXLQ3n"
      },
      "source": [
        "Comparer la performance du modèle Quantified aware training, au modèle original et au modèle quantifié post training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYOCqT2FLQ3o"
      },
      "outputs": [],
      "source": [
        "# On compare les performances sur le jeu de donnees de test\n",
        "# Evaluation du modele original\n",
        "original_test_loss, original_test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Evaluation du modele quantifie post training\n",
        "\n",
        "\n",
        "# Evaluation du modele Quantified aware training\n",
        "qat_test_loss, qat_test_acc = qat_model.evaluate(X_test, y_test)\n",
        "\n",
        "# Comparaison\n",
        "print(\"Test Loss : Original : \", original_test_loss, \" | Post Training : , pt_test_loss,  | Aware Training : \", qat_test_loss)\n",
        "print(\"Test Accuracy : Original :\", original_test_acc, \" | Post Training : , pt_test_acc,  | Aware Training : \", qat_test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBi1nf2CLQ3o"
      },
      "source": [
        "Sauvegarder le modèle QAT et comparer les tailles des modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-YpHm-0LQ3o"
      },
      "outputs": [],
      "source": [
        "joblib.dump(qat_tflite_model, \"qat_model.tflite\")\n",
        "\n",
        "qat_tflite_size = os.path.getsize(\"qat_model.tflite\")\n",
        "print(f\"\\nCe nouveau fichier qat_model.tflite fait {qat_tflite_size} octets.\")\n",
        "print(\"Il est donc plus petit que l ancien fichier.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo00Dl35FwTg"
      },
      "outputs": [],
      "source": [
        "!xxd -i qat_model.tflite > qat_model_data.cc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOMV5LNXHC-c"
      },
      "outputs": [],
      "source": [
        "!xxd -i qat_model.tflite > qat_model_data.h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5su4qx6oLQ3o"
      },
      "source": [
        "Bonus : déployer votre modèle sur votre téléphone ou un dispositif embarqué si vous en disposez d'un. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYwYzXbFLQ3o",
        "outputId": "387afb10-b325-4fc1-a6bd-7881dc658f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unsigned char qat_model_tflite[] = {\n",
            "  0x80, 0x04, 0x42, 0xb0, 0xc3, 0x06, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x54,\n",
            "  0x46, 0x4c, 0x33, 0x14, 0x00, 0x20, 0x00, 0x1c, 0x00, 0x18, 0x00, 0x14,\n",
            "  0x00, 0x10, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x14,\n",
            "  0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x90, 0x00, 0x00, 0x00, 0xe8,\n",
            "  0x00, 0x00, 0x00, 0x4c, 0xa6, 0x06, 0x00, 0x5c, 0xa6, 0x06, 0x00, 0xec,\n",
            "  0xc2, 0x06, 0x00, 0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x04,\n",
            "  0x00, 0x00, 0x00, 0x16, 0x56, 0xf9, 0xff, 0x0c, 0x00, 0x00, 0x00, 0x1c,\n",
            "  0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x73,\n",
            "  0x65, 0x72, 0x76, 0x69, 0x6e, 0x67, 0x5f, 0x64, 0x65, 0x66, 0x61, 0x75,\n",
            "  0x6c, 0x74, 0x00, 0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x8c,\n",
            "  0xff, 0xff, 0xff, 0x1d, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x0d,\n",
            "  0x00, 0x00, 0x00, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x5f, 0x64, 0x65, 0x6e,\n",
            "  0x73, 0x65, 0x5f, 0x31, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x04,\n",
            "  0x00, 0x00, 0x00, 0x5a, 0x59, 0xf9, 0xff, 0x04, 0x00, 0x00, 0x00, 0x0e,\n",
            "  0x00, 0x00, 0x00, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x31, 0x5f,\n",
            "  0x69, 0x6e, 0x70, 0x75, 0x74, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x34,\n",
            "  0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xdc, 0xff, 0xff, 0xff, 0x20,\n",
            "  0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00, 0x43,\n",
            "  0x4f, 0x4e, 0x56, 0x45, 0x52, 0x53, 0x49, 0x4f, 0x4e, 0x5f, 0x4d, 0x45,\n",
            "  0x54, 0x41, 0x44, 0x41, 0x54, 0x41, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x08,\n",
            "  0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00, 0x1f, 0x00, 0x00, 0x00, 0x04,\n",
            "  0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00, 0x6d, 0x69, 0x6e, 0x5f, 0x72,\n",
            "\u001b[K"
          ]
        }
      ],
      "source": [
        "!more qat_model_data.cc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTeV2FbxLQ3o"
      },
      "source": [
        "Bonus : Obtenir un modèle qui sera à la fois quantifié et élagué (prunned) en s'aidant de la documentation (https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YVJ1GmK4LQ3p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0aVeHw2LQ3p"
      },
      "source": [
        "A l'aide de tensorflow lite / tensorflow lite micro "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXYFT5s8LQ3p"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=0d51e245-899d-41d6-b23b-cf3e4bbbc6ea' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "fb1d23f975ba410e92fed9f5b8cbb7e6",
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}